"""
AI Detection API endpoints.

This module provides endpoints for detecting AI-generated text
from both direct text input and uploaded files.
"""

from typing import Annotated

from dishka import FromDishka
from dishka.integrations.fastapi import DishkaRoute
from fastapi import APIRouter, File, HTTPException, UploadFile, status, Depends

from src.api.v1.schemas.ai_detection import (
    AIDetectionResponse,
    DetectionResultSchema,
    DetectionSourceSchema,
    TextDetectionRequest,
)
from src.core.logging import get_logger
from src.dtos import AuthenticatedUserDTO
from src.dtos.ai_detection_dto import DetectionResult, DetectionSource
from src.services.ai_detection_service import AIDetectionService
from src.services.shared.auth_helpers import get_authenticated_user_dependency

logger = get_logger(__name__)

router = APIRouter(
    prefix="/ai-detection",
    route_class=DishkaRoute,
    tags=["AI Detection"],
)


def _map_detection_result_to_schema(result: DetectionResult) -> DetectionResultSchema:
    """Map DTO DetectionResult to schema DetectionResultSchema."""
    mapping = {
        DetectionResult.AI_GENERATED: DetectionResultSchema.AI_GENERATED,
        DetectionResult.HUMAN_WRITTEN: DetectionResultSchema.HUMAN_WRITTEN,
        DetectionResult.UNCERTAIN: DetectionResultSchema.UNCERTAIN,
    }
    return mapping[result]


def _map_detection_source_to_schema(source: DetectionSource) -> DetectionSourceSchema:
    """Map DTO DetectionSource to schema DetectionSourceSchema."""
    mapping = {
        DetectionSource.TEXT: DetectionSourceSchema.TEXT,
        DetectionSource.FILE: DetectionSourceSchema.FILE,
    }
    return mapping[source]


@router.post(
    "/detect-text",
    response_model=AIDetectionResponse,
    status_code=status.HTTP_200_OK,
    summary="Detect AI-generated text from input",
    description="Analyze provided text to determine if it was generated by AI or written by a human.",
)
async def detect_from_text(
    request: TextDetectionRequest,
    service: FromDishka[AIDetectionService],
    current_user: Annotated[AuthenticatedUserDTO, Depends(get_authenticated_user_dependency)],
):
    """
    Detect if provided text is AI-generated or human-written.

    **Request Body:**
    - `text`: Text to analyze (minimum 50 characters)

    **Response:**
    - `result`: Detection result (ai_generated, human_written, or uncertain)
    - `confidence`: Confidence score between 0.0 and 1.0
    - `text_preview`: Preview of analyzed text
    - `source`: Always "text" for this endpoint
    - `metadata`: Additional information about the analysis

    **Example:**
    ```json
    {
        "text": "Your text to analyze here..."
    }
    ```
    """
    try:
        logger.info(
            "detect_text_request",
            text_length=len(request.text),
            user_id=current_user.id,
            username=current_user.username
        )

        # Detect AI text
        result_dto = await service.detect_from_text(request.text)

        # Map DTO to response schema
        response = AIDetectionResponse(
            result=_map_detection_result_to_schema(result_dto.result),
            confidence=result_dto.confidence,
            text_preview=result_dto.text_preview,
            source=_map_detection_source_to_schema(result_dto.source),
            file_name=result_dto.file_name,
            metadata=result_dto.metadata,
        )

        logger.info(
            "detect_text_success",
            result=result_dto.result.value,
            confidence=result_dto.confidence,
            user_id=current_user.id
        )

        return response

    except ValueError as e:
        logger.warning(
            "detect_text_validation_error",
            error=str(e),
            user_id=current_user.id
        )
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=str(e)
        )
    except Exception as e:
        logger.error(
            "detect_text_failed",
            error=str(e),
            error_type=type(e).__name__,
            user_id=current_user.id,
            exc_info=True
        )
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Failed to detect AI text"
        )


@router.post(
    "/detect-file",
    response_model=AIDetectionResponse,
    status_code=status.HTTP_200_OK,
    summary="Detect AI-generated text from file",
    description="Upload a file (PDF, DOCX, TXT) to extract text and analyze if it was generated by AI.",
)
async def detect_from_file(
    file: Annotated[UploadFile, File(description="File to analyze (PDF, DOCX, DOC, TXT)")],
    service: FromDishka[AIDetectionService],
    current_user: Annotated[AuthenticatedUserDTO, Depends(get_authenticated_user_dependency)],
):
    """
    Detect if text in uploaded file is AI-generated or human-written.

    **Supported File Types:**
    - PDF (.pdf)
    - Microsoft Word (.docx, .doc)
    - Plain Text (.txt)

    **File Requirements:**
    - Maximum size: 20MB
    - Must contain at least 50 characters of text

    **Process:**
    1. File is uploaded and validated
    2. Text is extracted using Google Gemini AI
    3. Extracted text is analyzed by ML model
    4. Detection result is returned

    **Response:**
    - `result`: Detection result (ai_generated, human_written, or uncertain)
    - `confidence`: Confidence score between 0.0 and 1.0
    - `text_preview`: Preview of extracted text
    - `source`: Always "file" for this endpoint
    - `file_name`: Name of the uploaded file
    - `metadata`: File information and analysis details
    """
    try:
        logger.info(
            "detect_file_request",
            file_name=file.filename,
            content_type=file.content_type,
            user_id=current_user.id,
            username=current_user.username
        )

        # Read file content
        file_content = await file.read()

        if not file_content:
            raise ValueError("Uploaded file is empty")

        # Detect AI text from file
        result_dto = await service.detect_from_file(
            file_content=file_content,
            file_name=file.filename or "unknown",
            content_type=file.content_type or "application/octet-stream",
        )

        # Map DTO to response schema
        response = AIDetectionResponse(
            result=_map_detection_result_to_schema(result_dto.result),
            confidence=result_dto.confidence,
            text_preview=result_dto.text_preview,
            source=_map_detection_source_to_schema(result_dto.source),
            file_name=result_dto.file_name,
            metadata=result_dto.metadata,
        )

        logger.info(
            "detect_file_success",
            file_name=file.filename,
            result=result_dto.result.value,
            confidence=result_dto.confidence,
            user_id=current_user.id
        )

        return response

    except ValueError as e:
        logger.warning(
            "detect_file_validation_error",
            file_name=file.filename,
            error=str(e),
            user_id=current_user.id
        )
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=str(e)
        )
    except RuntimeError as e:
        logger.error(
            "detect_file_failed",
            file_name=file.filename,
            error=str(e),
            error_type=type(e).__name__,
            user_id=current_user.id,
            exc_info=True
        )
        raise HTTPException(
            status_code=status.HTTP_502_BAD_GATEWAY,
            detail="Text extraction service temporarily unavailable"
        )


@router.get(
    "/info",
    summary="Get AI detection service information",
    description="Returns information about supported file types and service limits.",
)
async def get_service_info():
    """
    Get information about the AI detection service.

    **Response includes:**
    - Supported file extensions
    - Maximum file size
    - Minimum text length
    - Available detection results
    """
    from src.core.gemini_config import gemini_config

    return {
        "supported_file_types": gemini_config.ALLOWED_FILE_EXTENSIONS,
        "max_file_size_mb": gemini_config.MAX_FILE_SIZE_MB,
        "min_text_length": 50,
        "detection_results": [
            "ai_generated",
            "human_written",
            "uncertain"
        ],
        "model_info": {
            "gemini_model": gemini_config.GEMINI_MODEL,
            "extraction_method": "Google Gemini AI",
            "detection_method": "ML Model (TODO: Replace with actual model)"
        }
    }